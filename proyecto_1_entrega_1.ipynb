{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceso de comprensión y preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recogida, comprensión y evaluación de calidad de datos\n",
    "Un problema que se identificó a priori es que el tipo de dato de SDG en el test set es float, cuando debería ser int. Por otro lado, hay muchos caracteres especiales que deben ser tratados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of training set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Textos_espanol</th>\n",
       "      <th>sdg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Por ejemplo, el nÃºmero de consultas externas ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>En 2007, el gobierno central financió directam...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Claramente, hay muchos otros factores en juego...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Por ejemplo, el estado australiano de Victoria...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El consumo anual de alcohol se estima en 15,7 ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Textos_espanol  sdg\n",
       "0  Por ejemplo, el nÃºmero de consultas externas ...    3\n",
       "1  En 2007, el gobierno central financió directam...    3\n",
       "2  Claramente, hay muchos otros factores en juego...    3\n",
       "3  Por ejemplo, el estado australiano de Victoria...    3\n",
       "4  El consumo anual de alcohol se estima en 15,7 ...    3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of test set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Textos_espanol</th>\n",
       "      <th>sdg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Han examinado la contribuciÃ³n de las univers...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>En la última década, y en particular desde 201...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>¿En qué países los estudiantes de alto rendimi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A raíz de su preocupación por el hecho de que ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999|H5|, Ares Abalde, 2014[ij]. El pequeño nú...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Textos_espanol  sdg\n",
       "0   Han examinado la contribuciÃ³n de las univers...  NaN\n",
       "1  En la última década, y en particular desde 201...  NaN\n",
       "2  ¿En qué países los estudiantes de alto rendimi...  NaN\n",
       "3  A raíz de su preocupación por el hecho de que ...  NaN\n",
       "4  1999|H5|, Ares Abalde, 2014[ij]. El pequeño nú...  NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of training set: (4049, 2)\n",
      "Shape of validation set: (702, 2)\n",
      "\n",
      "Info for training set:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4049 entries, 0 to 4048\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Textos_espanol  4049 non-null   object\n",
      " 1   sdg             4049 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 63.4+ KB\n",
      "\n",
      "Info for validation set:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 702 entries, 0 to 701\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Textos_espanol  702 non-null    object \n",
      " 1   sdg             0 non-null      float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 11.1+ KB\n",
      "\n",
      "Descriptive statistics for training set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Textos_espanol</th>\n",
       "      <th>sdg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4049</td>\n",
       "      <td>4049.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4049</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Las áreas útiles para un mayor estudio y acció...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.051124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Textos_espanol          sdg\n",
       "count                                                4049  4049.000000\n",
       "unique                                               4049          NaN\n",
       "top     Las áreas útiles para un mayor estudio y acció...          NaN\n",
       "freq                                                    1          NaN\n",
       "mean                                                  NaN     4.051124\n",
       "std                                                   NaN     0.814338\n",
       "min                                                   NaN     3.000000\n",
       "25%                                                   NaN     3.000000\n",
       "50%                                                   NaN     4.000000\n",
       "75%                                                   NaN     5.000000\n",
       "max                                                   NaN     5.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive statistics for validation set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Textos_espanol</th>\n",
       "      <th>sdg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>702</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>702</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Varios municipios describieron cómo trabajaron...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Textos_espanol  sdg\n",
       "count                                                 702  0.0\n",
       "unique                                                702  NaN\n",
       "top     Varios municipios describieron cómo trabajaron...  NaN\n",
       "freq                                                    1  NaN\n",
       "mean                                                  NaN  NaN\n",
       "std                                                   NaN  NaN\n",
       "min                                                   NaN  NaN\n",
       "25%                                                   NaN  NaN\n",
       "50%                                                   NaN  NaN\n",
       "75%                                                   NaN  NaN\n",
       "max                                                   NaN  NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for natural_text length in training set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    4049.000000\n",
       "mean      699.632502\n",
       "std       228.988965\n",
       "min       294.000000\n",
       "25%       531.000000\n",
       "50%       657.000000\n",
       "75%       827.000000\n",
       "max      1513.000000\n",
       "Name: Textos_espanol, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for natural_text length in validation set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     702.000000\n",
       "mean      693.564103\n",
       "std       219.593226\n",
       "min       338.000000\n",
       "25%       515.250000\n",
       "50%       665.500000\n",
       "75%       836.500000\n",
       "max      1468.000000\n",
       "Name: Textos_espanol, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of SDG categories in training set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sdg\n",
       "5    1451\n",
       "4    1354\n",
       "3    1244\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of SDG categories in test set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unusual characters in training set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " '*',\n",
       " '+',\n",
       " '/',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '@',\n",
       " '[',\n",
       " ']',\n",
       " '{',\n",
       " '|',\n",
       " '~',\n",
       " '¡',\n",
       " '¢',\n",
       " '£',\n",
       " '©',\n",
       " '«',\n",
       " '®',\n",
       " '°',\n",
       " '±',\n",
       " '»',\n",
       " '¿',\n",
       " '˜',\n",
       " '\\u200b',\n",
       " '–',\n",
       " '—',\n",
       " '’',\n",
       " '“',\n",
       " '”',\n",
       " '…',\n",
       " '€',\n",
       " '™'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unusual characters in validation set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'$',\n",
       " '%',\n",
       " '&',\n",
       " '*',\n",
       " '+',\n",
       " '/',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '|',\n",
       " '¡',\n",
       " '©',\n",
       " '«',\n",
       " '±',\n",
       " '»',\n",
       " '¿',\n",
       " '˜',\n",
       " '\\u200b',\n",
       " '—',\n",
       " '“',\n",
       " '”',\n",
       " '€',\n",
       " '™'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column names in training set: ['Textos_espanol', 'sdg']\n",
      "Column names in test: ['Textos_espanol', 'sdg']\n",
      "\n",
      "Data types in training set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Textos_espanol    object\n",
       "sdg                int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types in test set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Textos_espanol     object\n",
       "sdg               float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for duplicated rows within each file...\n",
      "\n",
      "Number of duplicated rows in training set: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Textos_espanol</th>\n",
       "      <th>sdg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Textos_espanol, sdg]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated rows in test set: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Textos_espanol</th>\n",
       "      <th>sdg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Textos_espanol, sdg]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for common rows between file1 and file2...\n",
      "Number of common rows between file1 and file2: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Textos_espanol</th>\n",
       "      <th>sdg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Textos_espanol, sdg]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No common rows found in both files.\n",
      "\n",
      "Missing values in training set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Textos_espanol    0\n",
       "sdg               0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in validation set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Textos_espanol      0\n",
       "sdg               702\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique labels in test set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 4, 5])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in validation set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "file1 = 'ODScat_345.csv' \n",
    "file2 = 'TestODScat_345.csv'  \n",
    "\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "\n",
    "# Functions\n",
    "def find_unusual_characters(df, column_name):\n",
    "    all_text = ' '.join(df[column_name].astype(str))\n",
    "    unusual_chars = re.findall(r'[^\\w\\s,.!?;:\\-()\\'\"]', all_text)\n",
    "    return set(unusual_chars)\n",
    "\n",
    "# Understanding\n",
    "print(\"First few rows of training set:\")\n",
    "display(df1.head())\n",
    "\n",
    "print(\"First few rows of test set:\")\n",
    "display(df2.head())\n",
    "\n",
    "print(\"\\nShape of training set:\", df1.shape)\n",
    "\n",
    "print(\"Shape of validation set:\", df2.shape)\n",
    "\n",
    "print(\"\\nInfo for training set:\")\n",
    "df1.info()\n",
    "print(\"\\nInfo for validation set:\")\n",
    "df2.info()\n",
    "\n",
    "print(\"\\nDescriptive statistics for training set:\")\n",
    "display(df1.describe(include='all')) \n",
    "\n",
    "print(\"\\nDescriptive statistics for validation set:\")\n",
    "display(df2.describe(include='all'))\n",
    "\n",
    "print(\"\\nBasic statistics for natural_text length in training set:\")\n",
    "display(df1['Textos_espanol'].str.len().describe())\n",
    "\n",
    "print(\"\\nBasic statistics for natural_text length in validation set:\")\n",
    "display(df2['Textos_espanol'].str.len().describe())\n",
    "\n",
    "print(\"Distribution of SDG categories in training set:\")\n",
    "distribution_file1 = df1['sdg'].value_counts()\n",
    "display(distribution_file1)\n",
    "\n",
    "print(\"\\nDistribution of SDG categories in test set:\")\n",
    "distribution_file2 = df2['sdg'].value_counts()\n",
    "display(distribution_file2)\n",
    "\n",
    "print(\"\\nUnusual characters in training set:\")\n",
    "unusual_chars_file1 = find_unusual_characters(df1, 'Textos_espanol')\n",
    "display(unusual_chars_file1)\n",
    "\n",
    "print(\"\\nUnusual characters in validation set:\")\n",
    "unusual_chars_file2 = find_unusual_characters(df2, 'Textos_espanol')\n",
    "display(unusual_chars_file2)\n",
    "\n",
    "# Consistency\n",
    "print(\"\\nColumn names in training set:\", df1.columns.tolist())\n",
    "print(\"Column names in test:\", df2.columns.tolist())\n",
    "\n",
    "print(\"\\nData types in training set:\")\n",
    "display(df1.dtypes)\n",
    "\n",
    "print(\"Data types in test set:\")\n",
    "display(df2.dtypes)\n",
    "\n",
    "# Uniqueness\n",
    "print(\"Checking for duplicated rows within each file...\\n\")\n",
    "\n",
    "duplicates_file1 = df1[df1.duplicated()]\n",
    "print(f\"Number of duplicated rows in training set: {len(duplicates_file1)}\")\n",
    "display(duplicates_file1)\n",
    "\n",
    "duplicates_file2 = df2[df2.duplicated()]\n",
    "print(f\"Number of duplicated rows in test set: {len(duplicates_file2)}\")\n",
    "display(duplicates_file2)\n",
    "\n",
    "print(\"\\nChecking for common rows between file1 and file2...\")\n",
    "\n",
    "common_rows = pd.merge(df1, df2, how='inner')\n",
    "print(f\"Number of common rows between file1 and file2: {len(common_rows)}\")\n",
    "display(common_rows)\n",
    "\n",
    "if len(common_rows) > 0:\n",
    "    print(\"\\nCommon rows found in both files:\")\n",
    "    display(common_rows)\n",
    "else:\n",
    "    print(\"\\nNo common rows found in both files.\")\n",
    "\n",
    "# Missing values\n",
    "print(\"\\nMissing values in training set:\")\n",
    "display(df1.isnull().sum())\n",
    "\n",
    "print(\"Missing values in validation set:\")\n",
    "display(df2.isnull().sum())\n",
    "\n",
    "# Validity\n",
    "print(\"\\nUnique labels in test set:\")\n",
    "display(df1['sdg'].unique())\n",
    "\n",
    "print(\"Unique labels in validation set:\")\n",
    "display(df2['sdg'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tranformación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza inicial del texto\n",
    "Al final quedan los tokens almacenados en el DF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/socub/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/socub/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/socub/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Textos_espanol</th>\n",
       "      <th>sdg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>tutori carrer disen apoy estudi consecucion ob...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>adem principal distincion sigi centr derech as...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>tambi detall conjunt integral polit practic ed...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>estudi cohort rein unid proporcion evident vin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>destac mayor cost oportun hij pronunci estrati...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>menud derech herenci viud reflej principi prop...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3011</th>\n",
       "      <td>curs financi tas regul mas elev crec numer aun...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>reduccion porcentaj afili sindicatosasoci trab...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>cambi cre mayor sinergi interaccion formacion ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>ecuador haiti nicaragu paraguay ejempl gast pu...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Textos_espanol  sdg\n",
       "1669  tutori carrer disen apoy estudi consecucion ob...    4\n",
       "2639  adem principal distincion sigi centr derech as...    5\n",
       "1673  tambi detall conjunt integral polit practic ed...    4\n",
       "739   estudi cohort rein unid proporcion evident vin...    3\n",
       "2443  destac mayor cost oportun hij pronunci estrati...    5\n",
       "2647  menud derech herenci viud reflej principi prop...    5\n",
       "3011  curs financi tas regul mas elev crec numer aun...    4\n",
       "2366  reduccion porcentaj afili sindicatosasoci trab...    5\n",
       "1125  cambi cre mayor sinergi interaccion formacion ...    4\n",
       "868   ecuador haiti nicaragu paraguay ejempl gast pu...    3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "stemmer = SnowballStemmer(\"spanish\")\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "    text = ''.join([c for c in text if not unicodedata.combining(c)])\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_words = [word for word in word_tokens if word.lower() not in stop_words]\n",
    "    stems = [stemmer.stem(word) for word in filtered_words]\n",
    "    return ' '.join(stems)\n",
    "\n",
    "df2['sdg'] = 0\n",
    "\n",
    "df1['Textos_espanol'] = df1['Textos_espanol'].apply(clean_text)\n",
    "df2['Textos_espanol'] = df2['Textos_espanol'].apply(clean_text)\n",
    "\n",
    "df1.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorización del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_par</th>\n",
       "      <th>a3ptim</th>\n",
       "      <th>a3rgan</th>\n",
       "      <th>aaad</th>\n",
       "      <th>aaadia3</th>\n",
       "      <th>aalt</th>\n",
       "      <th>aalton</th>\n",
       "      <th>aao</th>\n",
       "      <th>aaon</th>\n",
       "      <th>aaos</th>\n",
       "      <th>...</th>\n",
       "      <th>zogl</th>\n",
       "      <th>zoles</th>\n",
       "      <th>zoll</th>\n",
       "      <th>zomb</th>\n",
       "      <th>zon</th>\n",
       "      <th>zonmw</th>\n",
       "      <th>zuck</th>\n",
       "      <th>zukowski</th>\n",
       "      <th>zupanc</th>\n",
       "      <th>zusatzentgelt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2805</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3910</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 10594 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      _par  a3ptim  a3rgan  aaad  aaadia3  aalt  aalton  aao  aaon  aaos  ...  \\\n",
       "2805   0.0     0.0     0.0   0.0      0.0   0.0     0.0  0.0   0.0   0.0  ...   \n",
       "601    0.0     0.0     0.0   0.0      0.0   0.0     0.0  0.0   0.0   0.0  ...   \n",
       "3874   0.0     0.0     0.0   0.0      0.0   0.0     0.0  0.0   0.0   0.0  ...   \n",
       "250    0.0     0.0     0.0   0.0      0.0   0.0     0.0  0.0   0.0   0.0  ...   \n",
       "4007   0.0     0.0     0.0   0.0      0.0   0.0     0.0  0.0   0.0   0.0  ...   \n",
       "2016   0.0     0.0     0.0   0.0      0.0   0.0     0.0  0.0   0.0   0.0  ...   \n",
       "1477   0.0     0.0     0.0   0.0      0.0   0.0     0.0  0.0   0.0   0.0  ...   \n",
       "1428   0.0     0.0     0.0   0.0      0.0   0.0     0.0  0.0   0.0   0.0  ...   \n",
       "3910   0.0     0.0     0.0   0.0      0.0   0.0     0.0  0.0   0.0   0.0  ...   \n",
       "3390   0.0     0.0     0.0   0.0      0.0   0.0     0.0  0.0   0.0   0.0  ...   \n",
       "\n",
       "      zogl  zoles  zoll  zomb      zon  zonmw  zuck  zukowski  zupanc  \\\n",
       "2805   0.0    0.0   0.0   0.0  0.00000    0.0   0.0       0.0     0.0   \n",
       "601    0.0    0.0   0.0   0.0  0.00000    0.0   0.0       0.0     0.0   \n",
       "3874   0.0    0.0   0.0   0.0  0.00000    0.0   0.0       0.0     0.0   \n",
       "250    0.0    0.0   0.0   0.0  0.29168    0.0   0.0       0.0     0.0   \n",
       "4007   0.0    0.0   0.0   0.0  0.00000    0.0   0.0       0.0     0.0   \n",
       "2016   0.0    0.0   0.0   0.0  0.00000    0.0   0.0       0.0     0.0   \n",
       "1477   0.0    0.0   0.0   0.0  0.00000    0.0   0.0       0.0     0.0   \n",
       "1428   0.0    0.0   0.0   0.0  0.00000    0.0   0.0       0.0     0.0   \n",
       "3910   0.0    0.0   0.0   0.0  0.00000    0.0   0.0       0.0     0.0   \n",
       "3390   0.0    0.0   0.0   0.0  0.00000    0.0   0.0       0.0     0.0   \n",
       "\n",
       "      zusatzentgelt  \n",
       "2805            0.0  \n",
       "601             0.0  \n",
       "3874            0.0  \n",
       "250             0.0  \n",
       "4007            0.0  \n",
       "2016            0.0  \n",
       "1477            0.0  \n",
       "1428            0.0  \n",
       "3910            0.0  \n",
       "3390            0.0  \n",
       "\n",
       "[10 rows x 10594 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_tfidf_1 = tfidf_vectorizer.fit_transform(df1['Textos_espanol'])\n",
    "X_tfidf_2 = tfidf_vectorizer.transform(df2['Textos_espanol'])\n",
    "\n",
    "tfidf_df_1 = pd.DataFrame(X_tfidf_1.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "tfidf_df_2 = pd.DataFrame(X_tfidf_2.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "tfidf_df_1.sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label for the sample text: 4\n",
      "Original list of stems for sample index 0: examin contribucia3n univers institu educacia3n terciari desarroll capital human competent transferent tecnologa innovacia3n empresarial desarroll social cultural medioambiental creacia3n capac regional proces revisia3n facilit creacia3n asoci ciudad region reun institu educacia3n terciari organ paoblic priv identific objet estratag trabaj junt alcanz complement revision llev cab region transfronteriz mexicoest unid gran import estrateg econom nuev leon region pas nort mas recient sur arizon junt sonor\n",
      "Original text string for vectorization: e x a m i n   c o n t r i b u c i a 3 n   u n i v e r s   i n s t i t u   e d u c a c i a 3 n   t e r c i a r i   d e s a r r o l l   c a p i t a l   h u m a n   c o m p e t e n t   t r a n s f e r e n t   t e c n o l o g a   i n n o v a c i a 3 n   e m p r e s a r i a l   d e s a r r o l l   s o c i a l   c u l t u r a l   m e d i o a m b i e n t a l   c r e a c i a 3 n   c a p a c   r e g i o n a l   p r o c e s   r e v i s i a 3 n   f a c i l i t   c r e a c i a 3 n   a s o c i   c i u d a d   r e g i o n   r e u n   i n s t i t u   e d u c a c i a 3 n   t e r c i a r i   o r g a n   p a o b l i c   p r i v   i d e n t i f i c   o b j e t   e s t r a t a g   t r a b a j   j u n t   a l c a n z   c o m p l e m e n t   r e v i s i o n   l l e v   c a b   r e g i o n   t r a n s f r o n t e r i z   m e x i c o e s t   u n i d   g r a n   i m p o r t   e s t r a t e g   e c o n o m   n u e v   l e o n   r e g i o n   p a s   n o r t   m a s   r e c i e n t   s u r   a r i z o n   j u n t   s o n o r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/socub/Documents/U/BI/proyecto_1/env/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_train = df1['sdg']\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "clf.fit(tfidf_df_1, y_train)\n",
    "\n",
    "# Testing the model with tfidf_df_2\n",
    "# Example: Predict the label for the first text in tfidf_df_2\n",
    "sample_index = 0\n",
    "sample_text_vector = tfidf_df_2.iloc[sample_index].values.reshape(1, -1)\n",
    "predicted_label = clf.predict(sample_text_vector)\n",
    "\n",
    "print(f\"Predicted label for the sample text: {predicted_label[0]}\")\n",
    "\n",
    "original_stems = df2['Textos_espanol'].iloc[sample_index]\n",
    "\n",
    "original_text_str = ' '.join(original_stems)\n",
    "\n",
    "print(f\"Original list of stems for sample index {sample_index}: {original_stems}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
